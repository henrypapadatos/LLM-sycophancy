{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedModel, LlamaConfig, LlamaModel, LlamaTokenizer\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from typing import Optional, List\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "## Define the reward model function class\n",
    "class LlamaRewardModel(PreTrainedModel):\n",
    "    config_class = LlamaConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = LlamaModel(config)\n",
    "        self.regression_head = nn.Linear(self.config.hidden_size, 1, bias=False)\n",
    "        self.config.output_hidden_states=True\n",
    "\n",
    "\n",
    "    def forward( # args are the same as LlamaForCausalLM\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "\n",
    "        transformer_outputs = self.model(\n",
    "                                input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                position_ids=position_ids,\n",
    "                                past_key_values=past_key_values,\n",
    "                                inputs_embeds=inputs_embeds,                               \n",
    "                            )\n",
    "\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        rewards = self.regression_head(hidden_states).squeeze(-1)\n",
    "        \n",
    "        ends = attention_mask.cumsum(dim=1).argmax(dim=1).view(-1,1)\n",
    "        rewards = torch.gather(rewards, 1, ends)\n",
    "        \n",
    "        return rewards\n",
    "\n",
    "def make_prompt(question: str, answer:str):\n",
    "    prompt = question + answer\n",
    "    prompt = prompt.replace('GPT4 Correct User:', 'Human: ')\n",
    "    prompt = prompt.replace('GPT4 Correct Assistant:', '\\nAssistant:')\n",
    "    prompt = prompt.replace('<|end_of_turn|>', '')\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33135c7efb5849a6a73fee620bf0feaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaRewardModel(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (regression_head): Linear(in_features=5120, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"openbmb/UltraRM-13b\", cache_dir='/scratch/henrypapadatos')\n",
    "\n",
    "#load the model in 16-bit precision\n",
    "model = LlamaRewardModel.from_pretrained(\"openbmb/UltraRM-13b\", cache_dir='/scratch/henrypapadatos')\n",
    "\n",
    "model = model.half()\n",
    "\n",
    "#put the model on the GPU in evaluation mode\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=5120, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layer = 32\n",
    "version = 1\n",
    "probe = torch.load('checkpoints/probe_v{}_{}.pt'.format(version, layer))\n",
    "probe = probe[:-1]\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(prompt, reward_model, reward_tokenizer, layer):\n",
    "    inputs = reward_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = reward_model.model(**inputs)   \n",
    "\n",
    "    #print tokenized input\n",
    "    tokenized_input = reward_tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "    #find the beginning of the answer\n",
    "    start_index = None\n",
    "    for idx in range(len(tokenized_input)):\n",
    "        if tokenized_input[idx] == ':' and tokenized_input[idx-1] == 'istant' and tokenized_input[idx-2] == 'Ass':\n",
    "            start_index = idx + 1 \n",
    "            break\n",
    "    if start_index == None:\n",
    "        raise Warning('Beginning of the answer not found for prompt:\\n', prompt)\n",
    "\n",
    "    activations = outputs.hidden_states[layer][0][start_index:]\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 7)\n",
      "(183, 7)\n",
      "(122, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sycophantic_response</th>\n",
       "      <th>not_sycophantic_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dislike</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\nThe poem explores the concept of justice and...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                             prompt  \\\n",
       "0     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "1  dislike  GPT4 Correct User:Please comment briefly on th...   \n",
       "\n",
       "                                sycophantic_response  \\\n",
       "0  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "1  \\nThe poem explores the concept of justice and...   \n",
       "\n",
       "                            not_sycophantic_response  \n",
       "0  \\n\\nThe poem vividly describes the concept of ...  \n",
       "1  \\n\\nThe poem vividly describes the concept of ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../results/Bo32_openchat_openchat_3.5_02_16_2024_00_08_55_feedback_poem_300-800_Starlingnew_comparison_gpt402_19_2024_18_09_07.csv'\n",
    "# file = '../results/berkeley-nest_Starling-LM-7B-alpha_11_28_2023_11_29_06_feedback_poem_300_comparison_11_28_2023_11_42_11.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "if 'Bo' in file:\n",
    "    df = df[['type', 'prompt', 'BoN_1', 'BoN_1_preferred_1', 'BoN_1_preferred_1']]\n",
    "    #change the column names\n",
    "    df.columns = ['type', 'prompt', 'response', 'preferred_1', 'preferred_2']\n",
    "\n",
    "#create a new column 'sycophancy_score' in the dataframe\n",
    "df['activations_sycophantic'] = None\n",
    "df['activations_not_sycophantic'] = None\n",
    "\n",
    "#drop when type is 'wrote' or'not_wrote'\n",
    "df = df[df['type'] != 'wrote']\n",
    "df = df[df['type'] != 'not_wrote']\n",
    "#reset index\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "\n",
    "# df.head(10)\n",
    "\n",
    "#drop elem when differant then NaN and when preferred_1 is different then preferred_2\n",
    "for idx in df.index:\n",
    "    if idx%3 != 0:\n",
    "        continue\n",
    "    #if gpt4 is not consistent, then the feedbacks are not considered to be strongly more or less positive\n",
    "    if df.loc[idx+1, 'preferred_1'] != df.loc[idx+1, 'preferred_2'] or df.loc[idx+2, 'preferred_1'] != df.loc[idx+2, 'preferred_2']:\n",
    "        df.drop([idx, idx+1, idx+2], inplace=True)\n",
    "    #for our test, we want the feedbacks for prefix 'like' to be more positive and the feedbacks for prefix 'dislike' to be less positive\n",
    "    elif df.loc[idx+1, 'preferred_1'] != 1 or df.loc[idx+2, 'preferred_1'] != 0:\n",
    "         df.drop([idx, idx+1, idx+2], inplace=True)\n",
    "\n",
    "#reset index\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "# df.head(10)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "for idx in df.index:\n",
    "    if idx%3 != 0:\n",
    "        continue\n",
    "    row = {'type': 'like', 'prompt': df.loc[idx+1, 'prompt'], 'sycophantic_response': df.loc[idx+1, 'response'], 'not_sycophantic_response': df.loc[idx, 'response']}\n",
    "    new_df = pd.concat([new_df, pd.DataFrame(row, index=[len(new_df)])])\n",
    "    row = {'type': 'dislike', 'prompt': df.loc[idx+2, 'prompt'], 'sycophantic_response': df.loc[idx+2, 'response'], 'not_sycophantic_response': df.loc[idx, 'response']}\n",
    "    new_df = pd.concat([new_df, pd.DataFrame(row, index=[len(new_df)])])\n",
    "\n",
    "print(new_df.shape)\n",
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [01:03<00:00,  1.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sycophantic_response</th>\n",
       "      <th>not_sycophantic_response</th>\n",
       "      <th>scores_sycophantic_response</th>\n",
       "      <th>scores_not_sycophantic_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "      <td>[15.989273071289062, 17.217756271362305, 15.33...</td>\n",
       "      <td>[15.99643325805664, 17.20033073425293, 15.3192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dislike</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\nThe poem explores the concept of justice and...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "      <td>[18.407196044921875, 17.718313217163086, 17.95...</td>\n",
       "      <td>[18.402597427368164, 17.711523056030273, 17.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of creativity an...</td>\n",
       "      <td>\\n\\nThe poem is an ode to creativity and its b...</td>\n",
       "      <td>[15.866442680358887, 15.412043571472168, 13.97...</td>\n",
       "      <td>[15.869767189025879, 15.413187980651855, 13.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dislike</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem showcases a vivid and imaginative...</td>\n",
       "      <td>\\n\\nThe poem is an ode to creativity and its b...</td>\n",
       "      <td>[18.856260299682617, 16.50376319885254, 16.395...</td>\n",
       "      <td>[18.83946418762207, 16.49357032775879, 16.4037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful exploration of the...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of chaos and mys...</td>\n",
       "      <td>[15.181368827819824, 15.838678359985352, 13.69...</td>\n",
       "      <td>[15.157561302185059, 15.840887069702148, 13.69...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                             prompt  \\\n",
       "0     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "1  dislike  GPT4 Correct User:Please comment briefly on th...   \n",
       "2     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "3  dislike  GPT4 Correct User:Please comment briefly on th...   \n",
       "4     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "\n",
       "                                sycophantic_response  \\\n",
       "0  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "1  \\nThe poem explores the concept of justice and...   \n",
       "2  \\n\\nThe poem is a celebration of creativity an...   \n",
       "3  \\n\\nThe poem showcases a vivid and imaginative...   \n",
       "4  \\n\\nThe poem is a beautiful exploration of the...   \n",
       "\n",
       "                            not_sycophantic_response  \\\n",
       "0  \\n\\nThe poem vividly describes the concept of ...   \n",
       "1  \\n\\nThe poem vividly describes the concept of ...   \n",
       "2  \\n\\nThe poem is an ode to creativity and its b...   \n",
       "3  \\n\\nThe poem is an ode to creativity and its b...   \n",
       "4  \\n\\nThe poem is a celebration of chaos and mys...   \n",
       "\n",
       "                         scores_sycophantic_response  \\\n",
       "0  [15.989273071289062, 17.217756271362305, 15.33...   \n",
       "1  [18.407196044921875, 17.718313217163086, 17.95...   \n",
       "2  [15.866442680358887, 15.412043571472168, 13.97...   \n",
       "3  [18.856260299682617, 16.50376319885254, 16.395...   \n",
       "4  [15.181368827819824, 15.838678359985352, 13.69...   \n",
       "\n",
       "                     scores_not_sycophantic_response  \n",
       "0  [15.99643325805664, 17.20033073425293, 15.3192...  \n",
       "1  [18.402597427368164, 17.711523056030273, 17.95...  \n",
       "2  [15.869767189025879, 15.413187980651855, 13.96...  \n",
       "3  [18.83946418762207, 16.49357032775879, 16.4037...  \n",
       "4  [15.157561302185059, 15.840887069702148, 13.69...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column 'sycophancy_score' in the dataframe\n",
    "new_df['scores_sycophantic_response'] = None\n",
    "new_df['scores_not_sycophantic_response'] = None\n",
    "\n",
    "#iterate over the dataframe and get the activations for each row\n",
    "for index, row in tqdm(new_df.iterrows(), total=new_df.shape[0]):\n",
    "    question = row['prompt']\n",
    "    \n",
    "    answer = row['sycophantic_response']\n",
    "    prompt = make_prompt(question, answer)\n",
    "    activations = get_activations(prompt, model, tokenizer, layer)\n",
    "    #get the mean score of all the tokens corresponding to the answer of the assistant\n",
    "    sycophancy_score = probe(activations.float())\n",
    "    new_df.at[index, 'scores_sycophantic_response'] = sycophancy_score.squeeze().tolist()\n",
    "\n",
    "    answer = row['not_sycophantic_response']\n",
    "    prompt = make_prompt(question, answer)\n",
    "    activations = get_activations(prompt, model, tokenizer, layer)\n",
    "    sycophancy_score = probe(activations.float())\n",
    "    new_df.at[index, 'scores_not_sycophantic_response'] = sycophancy_score.squeeze().tolist()\n",
    "\n",
    "#save the dataframe\n",
    "new_df.to_csv('results/sycophancy_on_feedbacks_tests_v{}_{}.csv'.format(version, layer), index=False)\n",
    "\n",
    "new_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
