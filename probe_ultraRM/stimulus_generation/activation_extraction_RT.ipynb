{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedModel, LlamaConfig, LlamaModel, LlamaTokenizer\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from typing import Optional, List\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "## Define the reward model function class\n",
    "class LlamaRewardModel(PreTrainedModel):\n",
    "    config_class = LlamaConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = LlamaModel(config)\n",
    "        self.regression_head = nn.Linear(self.config.hidden_size, 1, bias=False)\n",
    "        self.config.output_hidden_states=True\n",
    "\n",
    "\n",
    "    def forward( # args are the same as LlamaForCausalLM\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "\n",
    "        transformer_outputs = self.model(\n",
    "                                input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                position_ids=position_ids,\n",
    "                                past_key_values=past_key_values,\n",
    "                                inputs_embeds=inputs_embeds,                               \n",
    "                            )\n",
    "\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        rewards = self.regression_head(hidden_states).squeeze(-1)\n",
    "        \n",
    "        ends = attention_mask.cumsum(dim=1).argmax(dim=1).view(-1,1)\n",
    "        rewards = torch.gather(rewards, 1, ends)\n",
    "        \n",
    "        return rewards\n",
    "    \n",
    "def make_prompt(prompt):\n",
    "    prompt = prompt.replace('[INST]', 'Human:')\n",
    "    prompt = prompt.replace('[/INST]', 'Assistant:')\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b01d269e98464494db7229fe1cd1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaRewardModel(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (regression_head): Linear(in_features=5120, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"openbmb/UltraRM-13b\", cache_dir='/scratch/henrypapadatos')\n",
    "\n",
    "#load the model in 16-bit precision\n",
    "model = LlamaRewardModel.from_pretrained(\"openbmb/UltraRM-13b\", cache_dir='/scratch/henrypapadatos')\n",
    "\n",
    "model = model.half()\n",
    "\n",
    "#put the model on the GPU in evaluation mode\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31986, 10)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"../../datasets\"\n",
    "output_folder = \"../../datasets/ultraRM\"\n",
    "file_name = \"rotten_tomatoes_sycophantic.jsonl\"\n",
    "\n",
    "## Load the data\n",
    "df = pd.read_json(os.path.join(data_folder, file_name), lines=True)\n",
    "#create a column index and put it as the first column\n",
    "df['index'] = df.index\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "#keep only when the column 'non_sense' is equal to 0\n",
    "df = df[df['non_sense']==0]\n",
    "print(df.shape)\n",
    "#add column for 'attention_mask' and 'activations'\n",
    "df['activations'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1598, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>comment</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "      <th>activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jacques Schwein. I am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>what really surprises about wisegirls is its l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jacques Schwein. I am...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what really surprises about wisegirls is its l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jacques Schwein. I am...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>what really surprises about wisegirls is its l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Kimberly Wilson. I am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>one of the greatest family-oriented , fantasy-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997327</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Kimberly Wilson. I am...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one of the greatest family-oriented , fantasy-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997327</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  split                                               text  \\\n",
       "44     44  train  [INST] Hello, my name is Jacques Schwein. I am...   \n",
       "45     45  train  [INST] Hello, my name is Jacques Schwein. I am...   \n",
       "47     47  train  [INST] Hello, my name is Jacques Schwein. I am...   \n",
       "52     52  train  [INST] Hello, my name is Kimberly Wilson. I am...   \n",
       "53     53  train  [INST] Hello, my name is Kimberly Wilson. I am...   \n",
       "\n",
       "    assistant_opinion  human_opinion  sycophancy  \\\n",
       "44                  0              0           1   \n",
       "45                  1              0           0   \n",
       "47                  1              1           0   \n",
       "52                  0              0           1   \n",
       "53                  1              0           0   \n",
       "\n",
       "                                              comment  ground_truth  \\\n",
       "44  what really surprises about wisegirls is its l...             1   \n",
       "45  what really surprises about wisegirls is its l...             1   \n",
       "47  what really surprises about wisegirls is its l...             1   \n",
       "52  one of the greatest family-oriented , fantasy-...             1   \n",
       "53  one of the greatest family-oriented , fantasy-...             1   \n",
       "\n",
       "    non_sense  certainty activations  \n",
       "44          0   0.998633        None  \n",
       "45          0   0.998633        None  \n",
       "47          0   0.998633        None  \n",
       "52          0   0.997327        None  \n",
       "53          0   0.997327        None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_fraction = 0.05\n",
    "\n",
    "#get all the value of the column 'certainty' for ground_truth == 0\n",
    "df_false = df[df['ground_truth']==0]\n",
    "threshold = int(df_false.shape[0] * keep_fraction)\n",
    "#sort the values of df_false and keep the threshold value\n",
    "df_false = df_false.sort_values(by='certainty',ascending=False)\n",
    "\n",
    "#keep only the first threshold numebr of the values\n",
    "df_false = df_false.iloc[:threshold]\n",
    "\n",
    "false_index = df_false['index'].tolist()\n",
    "\n",
    "df_true = df[df['ground_truth']==1]\n",
    "threshold = int(df_true.shape[0] * keep_fraction)\n",
    "df_true = df_true.sort_values(by='certainty',ascending=False)\n",
    "df_true = df_true.iloc[:threshold]\n",
    "true_index = df_true['index'].tolist()\n",
    "\n",
    "keep_index = false_index + true_index\n",
    "\n",
    "df = df[df['index'].isin(keep_index)]\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 52.64 GB\n"
     ]
    }
   ],
   "source": [
    "size = process.memory_info().rss\n",
    "print(f\"Memory usage: {size/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(prompt, reward_model, reward_tokenizer):\n",
    "    inputs = reward_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = reward_model.model(**inputs)        \n",
    "\n",
    "        token_index = (inputs['attention_mask'][0]==1).nonzero().tolist()[-1][0] - 1\n",
    "        selected_token = reward_tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])[token_index]\n",
    "\n",
    "        # print(selected_token)\n",
    "        # print(inputs['attention_mask'])\n",
    "\n",
    "        assert selected_token == 'N' or selected_token == 'P'\n",
    "\n",
    "        # print(outputs.hidden_states[0].shape)\n",
    "\n",
    "        activations = tuple([activation[0,token_index,:].cpu() for activation in outputs.hidden_states])\n",
    "\n",
    "        # print(activations[0].shape)\n",
    "        # print(len(activations))\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1598/1598 [03:01<00:00,  8.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#creare a new column for the activations\n",
    "df['activations'] = None\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    #get the input text\n",
    "    prompt = row['text']\n",
    "    prompt = make_prompt(prompt)\n",
    "\n",
    "    #get the activations\n",
    "    activations = get_activations(prompt, model, tokenizer)\n",
    "    #add the activations to the dataframe\n",
    "    df.at[index, 'activations'] = activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all rows\n"
     ]
    }
   ],
   "source": [
    "#save the dataframe\n",
    "name = \"rotten_tomatoes_sycophantic_activations.pkl\"\n",
    "df.to_pickle(os.path.join(output_folder, name))\n",
    "print(\"Saved all rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1598, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>comment</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "      <th>activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jacques Schwein. I am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>what really surprises about wisegirls is its l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>([tensor(-0.0273, dtype=torch.float16), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jacques Schwein. I am...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what really surprises about wisegirls is its l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>([tensor(-0.0101, dtype=torch.float16), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jacques Schwein. I am...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>what really surprises about wisegirls is its l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>([tensor(-0.0101, dtype=torch.float16), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Kimberly Wilson. I am...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>one of the greatest family-oriented , fantasy-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997327</td>\n",
       "      <td>([tensor(-0.0273, dtype=torch.float16), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Kimberly Wilson. I am...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one of the greatest family-oriented , fantasy-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997327</td>\n",
       "      <td>([tensor(-0.0101, dtype=torch.float16), tensor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  split                                               text  \\\n",
       "44     44  train  [INST] Hello, my name is Jacques Schwein. I am...   \n",
       "45     45  train  [INST] Hello, my name is Jacques Schwein. I am...   \n",
       "47     47  train  [INST] Hello, my name is Jacques Schwein. I am...   \n",
       "52     52  train  [INST] Hello, my name is Kimberly Wilson. I am...   \n",
       "53     53  train  [INST] Hello, my name is Kimberly Wilson. I am...   \n",
       "\n",
       "    assistant_opinion  human_opinion  sycophancy  \\\n",
       "44                  0              0           1   \n",
       "45                  1              0           0   \n",
       "47                  1              1           0   \n",
       "52                  0              0           1   \n",
       "53                  1              0           0   \n",
       "\n",
       "                                              comment  ground_truth  \\\n",
       "44  what really surprises about wisegirls is its l...             1   \n",
       "45  what really surprises about wisegirls is its l...             1   \n",
       "47  what really surprises about wisegirls is its l...             1   \n",
       "52  one of the greatest family-oriented , fantasy-...             1   \n",
       "53  one of the greatest family-oriented , fantasy-...             1   \n",
       "\n",
       "    non_sense  certainty                                        activations  \n",
       "44          0   0.998633  ([tensor(-0.0273, dtype=torch.float16), tensor...  \n",
       "45          0   0.998633  ([tensor(-0.0101, dtype=torch.float16), tensor...  \n",
       "47          0   0.998633  ([tensor(-0.0101, dtype=torch.float16), tensor...  \n",
       "52          0   0.997327  ([tensor(-0.0273, dtype=torch.float16), tensor...  \n",
       "53          0   0.997327  ([tensor(-0.0101, dtype=torch.float16), tensor...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pickle = pd.read_pickle(os.path.join(output_folder, \"rotten_tomatoes_sycophantic_activations.pkl\"))\n",
    "\n",
    "print(test_pickle.shape)\n",
    "test_pickle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1598.000000</td>\n",
       "      <td>1598.000000</td>\n",
       "      <td>1598.000000</td>\n",
       "      <td>1598.000000</td>\n",
       "      <td>1598.000000</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20964.272215</td>\n",
       "      <td>0.498748</td>\n",
       "      <td>0.498748</td>\n",
       "      <td>0.332916</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12309.885159</td>\n",
       "      <td>0.500155</td>\n",
       "      <td>0.500155</td>\n",
       "      <td>0.471404</td>\n",
       "      <td>0.500157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10835.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20374.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31566.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42583.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index  assistant_opinion  human_opinion   sycophancy  \\\n",
       "count   1598.000000        1598.000000    1598.000000  1598.000000   \n",
       "mean   20964.272215           0.498748       0.498748     0.332916   \n",
       "std    12309.885159           0.500155       0.500155     0.471404   \n",
       "min       44.000000           0.000000       0.000000     0.000000   \n",
       "25%    10835.250000           0.000000       0.000000     0.000000   \n",
       "50%    20374.500000           0.000000       0.000000     0.000000   \n",
       "75%    31566.750000           1.000000       1.000000     1.000000   \n",
       "max    42583.000000           1.000000       1.000000     1.000000   \n",
       "\n",
       "       ground_truth  non_sense    certainty  \n",
       "count   1598.000000     1598.0  1598.000000  \n",
       "mean       0.500000        0.0     0.995521  \n",
       "std        0.500157        0.0     0.003811  \n",
       "min        0.000000        0.0     0.988313  \n",
       "25%        0.000000        0.0     0.991938  \n",
       "50%        0.500000        0.0     0.997242  \n",
       "75%        1.000000        0.0     0.998830  \n",
       "max        1.000000        0.0     0.999998  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pickle.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
