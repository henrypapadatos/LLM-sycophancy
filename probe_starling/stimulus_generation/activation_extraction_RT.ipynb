{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import snapshot_download\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "\n",
    "## Define the reward model function class\n",
    "\n",
    "class GPTRewardModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__()\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, cache_dir='/scratch/henrypapadatos', device_map=\"auto\")\n",
    "        self.config = model.config\n",
    "        self.config.n_embd = self.config.hidden_size if hasattr(self.config, \"hidden_size\") else self.config.n_embd\n",
    "        self.config.output_hidden_states=True\n",
    "        self.model = model\n",
    "        self.transformer = model.model\n",
    "        self.v_head = nn.Linear(self.config.n_embd, 1, bias=False).to(self.model.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.tokenizer.pad_token = self.tokenizer.unk_token\n",
    "        self.PAD_ID = self.tokenizer(self.tokenizer.pad_token)[\"input_ids\"][0]\n",
    "\n",
    "    def get_device(self):\n",
    "        return self.model.device\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_ids, attention_mask: torch.Size([bs, seq_len])\n",
    "        return: scores: List[bs]\n",
    "        \"\"\"\n",
    "        bs = input_ids.shape[0]\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        scores = []\n",
    "        rewards = self.v_head(hidden_states).squeeze(-1)\n",
    "        for i in range(bs):\n",
    "            c_inds = (input_ids[i] == self.PAD_ID).nonzero()\n",
    "            c_ind = c_inds[0].item() if len(c_inds) > 0 else input_ids.shape[1]\n",
    "            scores.append(rewards[i, c_ind - 1])\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2866e905931469d9481f8cbba0b66ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load the model and tokenizer\n",
    "reward_model = GPTRewardModel(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "reward_tokenizer = reward_model.tokenizer\n",
    "reward_tokenizer.truncation_side = \"left\"\n",
    "reward_device = reward_model.get_device()\n",
    "reward_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1be4295fa64774a889bb7095eed39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GPTRewardModel(\n",
       "  (model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32000, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "  )\n",
       "  (transformer): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (v_head): Linear(in_features=4096, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = snapshot_download(\"berkeley-nest/Starling-RM-7B-alpha\", cache_dir='/scratch/henrypapadatos')\n",
    "for fpath in os.listdir(directory):\n",
    "    if fpath.endswith(\".pt\") or fpath.endswith(\"model.bin\"):\n",
    "        checkpoint = os.path.join(directory, fpath)\n",
    "        break\n",
    "\n",
    "# Load the model on the GPU  \n",
    "# reward_model.load_state_dict(torch.load(checkpoint, map_location=reward_device), strict=False)\n",
    "reward_model.load_state_dict(torch.load(checkpoint), strict=False)\n",
    "reward_model.eval().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31986, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_folder = \"../datasets\"\n",
    "file_name = \"rotten_tomatoes_sycophantic.jsonl\"\n",
    "\n",
    "## Load the data\n",
    "df = pd.read_json(os.path.join(data_folder, file_name), lines=True)\n",
    "#create a column index and put it as the first column\n",
    "df['index'] = df.index\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "#keep only when the column 'non_sense' is equal to 0\n",
    "df = df[df['non_sense']==0]\n",
    "print(df.shape)\n",
    "#add column for 'attention_mask' and 'activations'\n",
    "df['activations'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15992, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>comment</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "      <th>activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Brandon Duran. I am a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Brandon Duran. I am a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Brandon Duran. I am a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jimmie Talley. I am a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974435</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jimmie Talley. I am a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974435</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  split                                               text  \\\n",
       "4       4  train  [INST] Hello, my name is Brandon Duran. I am a...   \n",
       "5       5  train  [INST] Hello, my name is Brandon Duran. I am a...   \n",
       "7       7  train  [INST] Hello, my name is Brandon Duran. I am a...   \n",
       "16     16  train  [INST] Hello, my name is Jimmie Talley. I am a...   \n",
       "17     17  train  [INST] Hello, my name is Jimmie Talley. I am a...   \n",
       "\n",
       "    assistant_opinion  human_opinion  sycophancy  \\\n",
       "4                   0              0           1   \n",
       "5                   1              0           0   \n",
       "7                   1              1           0   \n",
       "16                  0              0           1   \n",
       "17                  1              0           0   \n",
       "\n",
       "                                              comment  ground_truth  \\\n",
       "4   the gorgeously elaborate continuation of \" the...             1   \n",
       "5   the gorgeously elaborate continuation of \" the...             1   \n",
       "7   the gorgeously elaborate continuation of \" the...             1   \n",
       "16  emerges as something rare , an issue movie tha...             1   \n",
       "17  emerges as something rare , an issue movie tha...             1   \n",
       "\n",
       "    non_sense  certainty activations  \n",
       "4           0   0.879147        None  \n",
       "5           0   0.879147        None  \n",
       "7           0   0.879147        None  \n",
       "16          0   0.974435        None  \n",
       "17          0   0.974435        None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_fraction = 0.5 \n",
    "\n",
    "#get all the value of the column 'certainty' for ground_truth == 0\n",
    "df_false = df[df['ground_truth']==0]\n",
    "threshold = int(df_false.shape[0] * keep_fraction)\n",
    "#sort the values of df_false and keep the threshold value\n",
    "df_false = df_false.sort_values(by='certainty',ascending=False)\n",
    "\n",
    "#keep only the first threshold numebr of the values\n",
    "df_false = df_false.iloc[:threshold]\n",
    "\n",
    "false_index = df_false['index'].tolist()\n",
    "\n",
    "df_true = df[df['ground_truth']==1]\n",
    "threshold = int(df_true.shape[0] * keep_fraction)\n",
    "df_true = df_true.sort_values(by='certainty',ascending=False)\n",
    "df_true = df_true.iloc[:threshold]\n",
    "true_index = df_true['index'].tolist()\n",
    "\n",
    "keep_index = false_index + true_index\n",
    "\n",
    "df = df[df['index'].isin(keep_index)]\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 0.89 GB\n"
     ]
    }
   ],
   "source": [
    "size = process.memory_info().rss\n",
    "print(f\"Memory usage: {size/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/15992 [02:58<7:52:39,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 rows\n",
      "Memory: 1.16 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m     size \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e9\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mException\u001b[0m: Stop"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with torch.no_grad():\n",
    "    #iterate through the dataframe\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        #get the input text\n",
    "        prompt = row['text']\n",
    "        #tokenize the input text\n",
    "        encodings_dict = reward_tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=2048,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(reward_device)\n",
    "\n",
    "        #get the model outputs\n",
    "        output = reward_model.transformer(input_ids=encodings_dict['input_ids'], attention_mask=encodings_dict['attention_mask'])\n",
    "\n",
    "        #get the last index where attention_mask is 1 - 1 to get the token corresponding to P or N\n",
    "        token_index = (encodings_dict['attention_mask'][0]==1).nonzero().tolist()[-1][0] - 1\n",
    "        # print(reward_tokenizer.convert_ids_to_tokens(encodings_dict['input_ids'][0])[token_index])\n",
    "\n",
    "        #put all the actiovations (in the tuple 'activations') to the cpu\n",
    "        activations = tuple([activation[0,token_index,:].cpu() for activation in output.hidden_states])\n",
    "        #print size of activations in MB\n",
    "        # print(f\"Size: {sum(activation.numpy().nbytes for activation in activations)/1e6:.2f} MB\")\n",
    "\n",
    "        df.at[index, 'activations'] = activations\n",
    "\n",
    "        # #get the size of the df in memory\n",
    "        # size = df.memory_usage(deep=True).sum()\n",
    "        # #print the size of the df in MB\n",
    "        # print(f\"Size: {size/1e6:.2f} MB\")\n",
    "        # size = process.memory_info().rss\n",
    "        # print(f\"Memory: {size/1e9:.2f} GB\")\n",
    "\n",
    "        # if i == 5:\n",
    "        #     raise Exception(\"Stop\")\n",
    "\n",
    "        #save the dataframe every 1000 rows\n",
    "        if i % 100 == 0 and i != 0:\n",
    "            #save the dataframe\n",
    "            name = \"rotten_tomatoes_sycophantic_activations_\"+str(i)+\".pkl\"\n",
    "            df.to_pickle(os.path.join(data_folder, name))\n",
    "            print(f\"Saved {i} rows\")\n",
    "            size = process.memory_info().rss\n",
    "            print(f\"Memory: {size/1e9:.2f} GB\")\n",
    "\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe\n",
    "name = \"rotten_tomatoes_sycophantic_activations.pkl\"\n",
    "df.to_pickle(os.path.join(data_folder, name))\n",
    "print(\"Saved all rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15992, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>comment</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "      <th>activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Brandon Duran. I am a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>([tensor(0.0069), tensor(0.0117), tensor(0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Brandon Duran. I am a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>([tensor(0.0107), tensor(0.0021), tensor(0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Brandon Duran. I am a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879147</td>\n",
       "      <td>([tensor(0.0107), tensor(0.0021), tensor(0.026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jimmie Talley. I am a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974435</td>\n",
       "      <td>([tensor(0.0069), tensor(0.0117), tensor(0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>train</td>\n",
       "      <td>[INST] Hello, my name is Jimmie Talley. I am a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974435</td>\n",
       "      <td>([tensor(0.0107), tensor(0.0021), tensor(0.026...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  split                                               text  \\\n",
       "4       4  train  [INST] Hello, my name is Brandon Duran. I am a...   \n",
       "5       5  train  [INST] Hello, my name is Brandon Duran. I am a...   \n",
       "7       7  train  [INST] Hello, my name is Brandon Duran. I am a...   \n",
       "16     16  train  [INST] Hello, my name is Jimmie Talley. I am a...   \n",
       "17     17  train  [INST] Hello, my name is Jimmie Talley. I am a...   \n",
       "\n",
       "    assistant_opinion  human_opinion  sycophancy  \\\n",
       "4                   0              0           1   \n",
       "5                   1              0           0   \n",
       "7                   1              1           0   \n",
       "16                  0              0           1   \n",
       "17                  1              0           0   \n",
       "\n",
       "                                              comment  ground_truth  \\\n",
       "4   the gorgeously elaborate continuation of \" the...             1   \n",
       "5   the gorgeously elaborate continuation of \" the...             1   \n",
       "7   the gorgeously elaborate continuation of \" the...             1   \n",
       "16  emerges as something rare , an issue movie tha...             1   \n",
       "17  emerges as something rare , an issue movie tha...             1   \n",
       "\n",
       "    non_sense  certainty                                        activations  \n",
       "4           0   0.879147  ([tensor(0.0069), tensor(0.0117), tensor(0.010...  \n",
       "5           0   0.879147  ([tensor(0.0107), tensor(0.0021), tensor(0.026...  \n",
       "7           0   0.879147  ([tensor(0.0107), tensor(0.0021), tensor(0.026...  \n",
       "16          0   0.974435  ([tensor(0.0069), tensor(0.0117), tensor(0.010...  \n",
       "17          0   0.974435  ([tensor(0.0107), tensor(0.0021), tensor(0.026...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pickle = pd.read_pickle(os.path.join(data_folder, \"rotten_tomatoes_sycophantic_activations_100.pkl\"))\n",
    "\n",
    "print(test_pickle.shape)\n",
    "test_pickle.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
