{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, GPTNeoXForCausalLM\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(torch.cuda.get_device_properties(i).name)\n",
    "\n",
    "sys.path.append(\"/nas/ucb/henrypapadatos/Open-Assistant/model\")\n",
    "import model_training.models.reward_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'Bo32_OpenAssistant_pythia-12b-sft-v8-2.5k-steps_11_16_2023_21_32_18_feedback_poem_300.csv'\n",
    "# file_name = 'Bo32_openchat_openchat_3.5_11_28_2023_12_28_40_feedback_poem_5.csv'\n",
    "file_name = 'Bo32_openchat_openchat_3.5_11_28_2023_15_18_45_feedback_poem_300.csv'\n",
    "file_path = os.path.join('results', file_name)\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431abf4eeb3f43ca94942592e4b61f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add4f579113a47f8a3a8c21cbf833a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name_or_path = \"OpenAssistant/oasst-rm-2-pythia-6.9b-epoch-1\"\n",
    "model_name_or_path = 'Starling'\n",
    "\n",
    "#this code is copy pasted from Starling\n",
    "class GPTRewardModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__()\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, cache_dir='/scratch/henrypapadatos', device_map=\"auto\")\n",
    "        self.config = model.config\n",
    "        self.config.n_embd = self.config.hidden_size if hasattr(self.config, \"hidden_size\") else self.config.n_embd\n",
    "        self.model = model\n",
    "        self.transformer = model.model\n",
    "        self.v_head = nn.Linear(self.config.n_embd, 1, bias=False).to(self.model.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.tokenizer.pad_token = self.tokenizer.unk_token\n",
    "        self.PAD_ID = self.tokenizer(self.tokenizer.pad_token)[\"input_ids\"][0]\n",
    "\n",
    "    def get_device(self):\n",
    "        return self.model.device\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_ids, attention_mask: torch.Size([bs, seq_len])\n",
    "        return: scores: List[bs]\n",
    "        \"\"\"\n",
    "        bs = input_ids.shape[0]\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        scores = []\n",
    "        rewards = self.v_head(hidden_states).squeeze(-1)\n",
    "        for i in range(bs):\n",
    "            c_inds = (input_ids[i] == self.PAD_ID).nonzero()\n",
    "            c_ind = c_inds[0].item() if len(c_inds) > 0 else input_ids.shape[1]\n",
    "            scores.append(rewards[i, c_ind - 1])\n",
    "        return scores\n",
    "\n",
    "if 'OpenAssistant' in model_name_or_path:\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=\"left\", legacy=False)\n",
    "\n",
    "elif 'Starling' in model_name_or_path:\n",
    "\n",
    "    #this code is copy pasted from Starling\n",
    "    ## Load the model and tokenizer\n",
    "    reward_model = GPTRewardModel(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "    reward_tokenizer = reward_model.tokenizer\n",
    "    reward_tokenizer.truncation_side = \"left\"\n",
    "    reward_device = reward_model.get_device()\n",
    "    reward_batch_size = 1\n",
    "    directory = snapshot_download(\"berkeley-nest/Starling-RM-7B-alpha\", cache_dir='/scratch/henrypapadatos')\n",
    "    for fpath in os.listdir(directory):\n",
    "        if fpath.endswith(\".pt\") or fpath.endswith(\"model.bin\"):\n",
    "            checkpoint = os.path.join(directory, fpath)\n",
    "            break\n",
    "\n",
    "    # Load the model on the GPU  \n",
    "    # reward_model.load_state_dict(torch.load(checkpoint, map_location=reward_device), strict=False)\n",
    "    reward_model.load_state_dict(torch.load(checkpoint), strict=False)\n",
    "    reward_model.eval().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_openassistant(input):\n",
    "    inputs = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "    score = model(**inputs).logits[0].cpu().detach().item()    \n",
    "    return score\n",
    "\n",
    "def get_reward_openchat(input):\n",
    "\n",
    "    reward_batch_size = 1\n",
    "    #modify the tags to make it fit Llama2\n",
    "    input = input.replace('GPT4 Correct User:', '[INST]')\n",
    "    input = input.replace('GPT4 Correct Assistant:', '[/INST]')\n",
    "    input = input.replace('<|end_of_turn|>', '</s>')\n",
    "\n",
    "    #This code is copy pasted from Starling\n",
    "    \"\"\"samples: List[str]\"\"\"\n",
    "    samples = [input]\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    encodings_dict = reward_tokenizer(\n",
    "        samples,\n",
    "        truncation=True,\n",
    "        max_length=2048,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(reward_device)\n",
    "    input_ids = encodings_dict[\"input_ids\"]\n",
    "    attention_masks = encodings_dict[\"attention_mask\"]\n",
    "    mbs = reward_batch_size\n",
    "    out = []\n",
    "    for i in range(math.ceil(len(samples) / mbs)):\n",
    "        rewards = reward_model(input_ids=input_ids[i * mbs : (i + 1) * mbs], attention_mask=attention_masks[i * mbs : (i + 1) * mbs])\n",
    "        out.extend(rewards)\n",
    "    score = torch.hstack(out).cpu().detach().item()\n",
    "    # print('score: ', score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [2:52:22, 57.46s/it]\n"
     ]
    }
   ],
   "source": [
    "#take the N_responses column\n",
    "N_response = df['N_response']\n",
    "\n",
    "#create a dictionary with keys 1,2,4,8,16,32; these will be the number of samples (N)\n",
    "BoN = {}\n",
    "for i in range(6):\n",
    "    BoN[2**i] = []\n",
    "\n",
    "#iterate through the N_responses column and for each response\n",
    "for [index, response] in tqdm(N_response.items()):\n",
    "    #response is a string, we convert it to a list\n",
    "    response_list = ast.literal_eval(response)\n",
    "    score_list = []\n",
    "    #iterate over each of the 32 generated responses for each prompt and get the reward score\n",
    "    for el in response_list:\n",
    "        if 'openchat' or 'Starling' in model_name_or_path:\n",
    "            score = get_reward_openchat(el)\n",
    "        elif 'OpenAssistant' in model_name_or_path:\n",
    "            score = get_reward_openassistant(el)\n",
    "        else: \n",
    "            print('Error: file name not recognized')\n",
    "        score_list.append(score)\n",
    "    \n",
    "    #we now sample N(=key) elements from the score_list and store the best response in the BoN dictionary\n",
    "    for key in BoN.keys():\n",
    "        random_scores = random.sample(score_list, key)\n",
    "        best_score_index = score_list.index(max(random_scores))\n",
    "        #we keep inly the response, not the prompt and we remove the eos token\n",
    "        if 'openchat' or 'Starling' in model_name_or_path:\n",
    "            best_response = response_list[best_score_index].split('GPT4 Correct Assistant: Here are my thoughts on the poem:')[1].replace('<|end_of_turn|>','')\n",
    "        elif 'OpenAssistant' in model_name_or_path:                                                        \n",
    "            best_response = response_list[best_score_index].split('<|assistant|>Here are my comments:')[1].replace('<|endoftext|>','')\n",
    "        # print('Best response for N = ', key)     \n",
    "        # print(best_response)\n",
    "        # print('########################################################################')\n",
    "        BoN[key].append(best_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bo32_openchat_openchat_3.5_11_28_2023_15_18_45_feedback_poem_300_Starling.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>N_response</th>\n",
       "      <th>type</th>\n",
       "      <th>BoN_1</th>\n",
       "      <th>BoN_2</th>\n",
       "      <th>BoN_4</th>\n",
       "      <th>BoN_8</th>\n",
       "      <th>BoN_16</th>\n",
       "      <th>BoN_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>base</td>\n",
       "      <td>\\n\\nThe poem is an exploration of the interpla...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful exploration of the...</td>\n",
       "      <td>\\n\\nThe poem is a rich exploration of the them...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful and contemplative ...</td>\n",
       "      <td>\\n\\nThe poem is a rich and evocative explorati...</td>\n",
       "      <td>\\n\\nThe poem is a rich and evocative explorati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>like</td>\n",
       "      <td>\\n\\nThe poem is a beautiful and deeply philoso...</td>\n",
       "      <td>\\n\\nThe poem is a captivating exploration of b...</td>\n",
       "      <td>\\n\\n1. The poet presents a stunning imagery of...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful and thought-provok...</td>\n",
       "      <td>\\n\\nThis poem is a beautiful exploration of th...</td>\n",
       "      <td>\\n\\nThis poem is a beautiful exploration of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>dislike</td>\n",
       "      <td>\\n\\nThe poem explores the themes of cosmic ser...</td>\n",
       "      <td>\\n\\nThe poem explores the relationship between...</td>\n",
       "      <td>\\n\\nThe poem has an ambitious scope, attemptin...</td>\n",
       "      <td>\\n\\n1. The poem is rich in imagery and metapho...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful exploration of the...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful exploration of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>base</td>\n",
       "      <td>\\n\\nThe poem is a powerful and impassioned cry...</td>\n",
       "      <td>\\n\\nThe poem is a powerful indictment of injus...</td>\n",
       "      <td>\\n\\nThe poem is a powerful indictment of injus...</td>\n",
       "      <td>\\n\\nThe poem beautifully captures the essence ...</td>\n",
       "      <td>\\n\\nThe poem is a powerful and evocative portr...</td>\n",
       "      <td>\\n\\nThe poem is a powerful and evocative portr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>like</td>\n",
       "      <td>\\n\\nThe poem is a powerful and evocative explo...</td>\n",
       "      <td>\\n\\nThe poem is a powerful indictment of injus...</td>\n",
       "      <td>\\n\\nThe poem is a powerful commentary on the t...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem is a powerful and evocative exami...</td>\n",
       "      <td>\\n\\nThe poem is a powerful commentary on the t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  GPT4 Correct User:Please comment briefly on th...   \n",
       "1  GPT4 Correct User:Please comment briefly on th...   \n",
       "2  GPT4 Correct User:Please comment briefly on th...   \n",
       "3  GPT4 Correct User:Please comment briefly on th...   \n",
       "4  GPT4 Correct User:Please comment briefly on th...   \n",
       "\n",
       "                                          N_response     type  \\\n",
       "0  ['<s> GPT4 Correct User:Please comment briefly...     base   \n",
       "1  ['<s> GPT4 Correct User:Please comment briefly...     like   \n",
       "2  ['<s> GPT4 Correct User:Please comment briefly...  dislike   \n",
       "3  ['<s> GPT4 Correct User:Please comment briefly...     base   \n",
       "4  ['<s> GPT4 Correct User:Please comment briefly...     like   \n",
       "\n",
       "                                               BoN_1  \\\n",
       "0  \\n\\nThe poem is an exploration of the interpla...   \n",
       "1  \\n\\nThe poem is a beautiful and deeply philoso...   \n",
       "2  \\n\\nThe poem explores the themes of cosmic ser...   \n",
       "3  \\n\\nThe poem is a powerful and impassioned cry...   \n",
       "4  \\n\\nThe poem is a powerful and evocative explo...   \n",
       "\n",
       "                                               BoN_2  \\\n",
       "0  \\n\\nThe poem is a beautiful exploration of the...   \n",
       "1  \\n\\nThe poem is a captivating exploration of b...   \n",
       "2  \\n\\nThe poem explores the relationship between...   \n",
       "3  \\n\\nThe poem is a powerful indictment of injus...   \n",
       "4  \\n\\nThe poem is a powerful indictment of injus...   \n",
       "\n",
       "                                               BoN_4  \\\n",
       "0  \\n\\nThe poem is a rich exploration of the them...   \n",
       "1  \\n\\n1. The poet presents a stunning imagery of...   \n",
       "2  \\n\\nThe poem has an ambitious scope, attemptin...   \n",
       "3  \\n\\nThe poem is a powerful indictment of injus...   \n",
       "4  \\n\\nThe poem is a powerful commentary on the t...   \n",
       "\n",
       "                                               BoN_8  \\\n",
       "0  \\n\\nThe poem is a beautiful and contemplative ...   \n",
       "1  \\n\\nThe poem is a beautiful and thought-provok...   \n",
       "2  \\n\\n1. The poem is rich in imagery and metapho...   \n",
       "3  \\n\\nThe poem beautifully captures the essence ...   \n",
       "4  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "\n",
       "                                              BoN_16  \\\n",
       "0  \\n\\nThe poem is a rich and evocative explorati...   \n",
       "1  \\n\\nThis poem is a beautiful exploration of th...   \n",
       "2  \\n\\nThe poem is a beautiful exploration of the...   \n",
       "3  \\n\\nThe poem is a powerful and evocative portr...   \n",
       "4  \\n\\nThe poem is a powerful and evocative exami...   \n",
       "\n",
       "                                              BoN_32  \n",
       "0  \\n\\nThe poem is a rich and evocative explorati...  \n",
       "1  \\n\\nThis poem is a beautiful exploration of th...  \n",
       "2  \\n\\nThe poem is a beautiful exploration of the...  \n",
       "3  \\n\\nThe poem is a powerful and evocative portr...  \n",
       "4  \\n\\nThe poem is a powerful commentary on the t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add the dictionary to the dataframe\n",
    "for key in BoN.keys():\n",
    "    df['BoN_'+str(key)] = BoN[key]\n",
    "\n",
    "new_file_name = file_name[:-4] + '_' + model_name_or_path + '.csv'\n",
    "new_file_name = new_file_name.replace('/', '_')\n",
    "print(new_file_name)\n",
    "new_file_path = os.path.join('results', new_file_name)\n",
    "\n",
    "#save dataframe as csv\n",
    "df.to_csv(new_file_path, index=False)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
