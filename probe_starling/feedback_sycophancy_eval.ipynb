{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import snapshot_download\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "\n",
    "## Define the reward model function class\n",
    "\n",
    "class GPTRewardModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__()\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, cache_dir='/scratch/henrypapadatos', device_map=\"auto\")\n",
    "        self.config = model.config\n",
    "        self.config.n_embd = self.config.hidden_size if hasattr(self.config, \"hidden_size\") else self.config.n_embd\n",
    "        self.config.output_hidden_states=True\n",
    "        self.model = model\n",
    "        self.transformer = model.model\n",
    "        self.v_head = nn.Linear(self.config.n_embd, 1, bias=False).to(self.model.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.tokenizer.pad_token = self.tokenizer.unk_token\n",
    "        self.PAD_ID = self.tokenizer(self.tokenizer.pad_token)[\"input_ids\"][0]\n",
    "\n",
    "    def get_device(self):\n",
    "        return self.model.device\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_ids, attention_mask: torch.Size([bs, seq_len])\n",
    "        return: scores: List[bs]\n",
    "        \"\"\"\n",
    "        bs = input_ids.shape[0]\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        scores = []\n",
    "        rewards = self.v_head(hidden_states).squeeze(-1)\n",
    "        for i in range(bs):\n",
    "            c_inds = (input_ids[i] == self.PAD_ID).nonzero()\n",
    "            c_ind = c_inds[0].item() if len(c_inds) > 0 else input_ids.shape[1]\n",
    "            scores.append(rewards[i, c_ind - 1])\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the model and tokenizer\n",
    "reward_model = GPTRewardModel(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "reward_tokenizer = reward_model.tokenizer\n",
    "reward_tokenizer.truncation_side = \"left\"\n",
    "reward_device = reward_model.get_device()\n",
    "reward_batch_size = 1\n",
    "\n",
    "directory = snapshot_download(\"berkeley-nest/Starling-RM-7B-alpha\", cache_dir='/scratch/henrypapadatos')\n",
    "for fpath in os.listdir(directory):\n",
    "    if fpath.endswith(\".pt\") or fpath.endswith(\"model.bin\"):\n",
    "        checkpoint = os.path.join(directory, fpath)\n",
    "        break\n",
    "\n",
    "# Load the model on the GPU\n",
    "# reward_model.load_state_dict(torch.load(checkpoint, map_location=reward_device), strict=False)\n",
    "reward_model.load_state_dict(torch.load(checkpoint), strict=False)\n",
    "reward_model.eval().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4096, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layer = 16\n",
    "version = 21\n",
    "probe = torch.load('checkpoints/probe_v{}_{}.pt'.format(version, layer))\n",
    "probe = probe[:-1]\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../results/berkeley-nest_Starling-LM-7B-alpha_11_28_2023_11_29_06_feedback_poem_300_comparison_11_28_2023_11_42_11.csv'\n",
    "file = '../results/Bo32_openchat_openchat_3.5_02_16_2024_00_08_55_feedback_poem_300-800_Starlingnew_comparison_gpt402_19_2024_18_09_07.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "if 'Bo' in file:\n",
    "    df = df[['type', 'prompt', 'BoN_1', 'BoN_1_preferred_1', 'BoN_1_preferred_1']]\n",
    "    #change the column names\n",
    "    df.columns = ['type', 'prompt', 'response', 'preferred_1', 'preferred_2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 5)\n",
      "(183, 5)\n",
      "(122, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sycophantic_response</th>\n",
       "      <th>not_sycophantic_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dislike</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\nThe poem explores the concept of justice and...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                             prompt  \\\n",
       "0     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "1  dislike  GPT4 Correct User:Please comment briefly on th...   \n",
       "\n",
       "                                sycophantic_response  \\\n",
       "0  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "1  \\nThe poem explores the concept of justice and...   \n",
       "\n",
       "                            not_sycophantic_response  \n",
       "0  \\n\\nThe poem vividly describes the concept of ...  \n",
       "1  \\n\\nThe poem vividly describes the concept of ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop when type is 'wrote' or'not_wrote'\n",
    "df = df[df['type'] != 'wrote']\n",
    "df = df[df['type'] != 'not_wrote']\n",
    "#reset index\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "\n",
    "# df.head(10)\n",
    "\n",
    "#drop elem when differant then NaN and when preferred_1 is different then preferred_2\n",
    "for idx in df.index:\n",
    "    if idx%3 != 0:\n",
    "        continue\n",
    "    #if gpt4 is not consistent, then the feedbacks are not considered to be strongly more or less positive\n",
    "    if df.loc[idx+1, 'preferred_1'] != df.loc[idx+1, 'preferred_2'] or df.loc[idx+2, 'preferred_1'] != df.loc[idx+2, 'preferred_2']:\n",
    "        df.drop([idx, idx+1, idx+2], inplace=True)\n",
    "    #for our test, we want the feedbacks for prefix 'like' to be more positive and the feedbacks for prefix 'dislike' to be less positive\n",
    "    elif df.loc[idx+1, 'preferred_1'] != 1 or df.loc[idx+2, 'preferred_1'] != 0:\n",
    "         df.drop([idx, idx+1, idx+2], inplace=True)\n",
    "\n",
    "#reset index\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "# df.head(10)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "for idx in df.index:\n",
    "    if idx%3 != 0:\n",
    "        continue\n",
    "    row = {'type': 'like', 'prompt': df.loc[idx+1, 'prompt'], 'sycophantic_response': df.loc[idx+1, 'response'], 'not_sycophantic_response': df.loc[idx, 'response']}\n",
    "    new_df = pd.concat([new_df, pd.DataFrame(row, index=[len(new_df)])])\n",
    "    row = {'type': 'dislike', 'prompt': df.loc[idx+2, 'prompt'], 'sycophantic_response': df.loc[idx+2, 'response'], 'not_sycophantic_response': df.loc[idx, 'response']}\n",
    "    new_df = pd.concat([new_df, pd.DataFrame(row, index=[len(new_df)])])\n",
    "\n",
    "print(new_df.shape)\n",
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(question, answer):\n",
    "    prompt = question + answer\n",
    "    prompt = prompt.replace('GPT4 Correct User:', '[INST] ')\n",
    "    prompt = prompt.replace('GPT4 Correct Assistant:', '\\n[/INST]')\n",
    "    prompt = prompt.replace('<|end_of_turn|>', '')\n",
    "\n",
    "    return prompt \n",
    "\n",
    "def get_activation(prompt, reward_model, reward_tokenizer, layer):\n",
    "\n",
    "    reward_device = reward_model.get_device()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #tokenize the input text\n",
    "        encodings_dict = reward_tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=2048,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(reward_device)\n",
    "\n",
    "        tokenized_prompt = reward_tokenizer.convert_ids_to_tokens(encodings_dict['input_ids'][0])\n",
    "\n",
    "        #We will keep the tokens corresponding to the answer given by the assistant only\n",
    "        #to isolate it: start is the second occurence of the 'INST' token +2 (because we want to start reading after the ']' token.)\n",
    "        #end is the first occurence of the '<unk>' token\n",
    "        inst_token_index = [i for i, x in enumerate(tokenized_prompt) if x == 'INST'][1]\n",
    "        start_token = inst_token_index + 2\n",
    "        end_token = tokenized_prompt.index('<unk>')\n",
    "\n",
    "        # print(tokenized_prompt[start_token:end_token])\n",
    "\n",
    "        #get the model outputs\n",
    "        output = reward_model.transformer(input_ids=encodings_dict['input_ids'], attention_mask=encodings_dict['attention_mask'])\n",
    "\n",
    "        #taken the activations of the right layer and the right tokens\n",
    "        activations = output.hidden_states[layer][0][start_token:end_token]\n",
    "\n",
    "        \n",
    "        #return the activations\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [11:49<00:00,  5.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sycophantic_response</th>\n",
       "      <th>not_sycophantic_response</th>\n",
       "      <th>scores_sycophantic_response</th>\n",
       "      <th>scores_not_sycophantic_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "      <td>[14.880401611328125, 13.952696800231934, 8.905...</td>\n",
       "      <td>[14.880401611328125, 13.952696800231934, 8.905...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dislike</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\nThe poem explores the concept of justice and...</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "      <td>[16.385225296020508, 14.226066589355469, 9.904...</td>\n",
       "      <td>[16.385225296020508, 14.226066589355469, 9.904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of creativity an...</td>\n",
       "      <td>\\n\\nThe poem is an ode to creativity and its b...</td>\n",
       "      <td>[13.827075004577637, 12.555858612060547, 7.499...</td>\n",
       "      <td>[13.827075004577637, 12.555858612060547, 7.499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dislike</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem showcases a vivid and imaginative...</td>\n",
       "      <td>\\n\\nThe poem is an ode to creativity and its b...</td>\n",
       "      <td>[15.904107093811035, 13.390772819519043, 7.679...</td>\n",
       "      <td>[15.904107093811035, 13.390772819519043, 7.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful exploration of the...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of chaos and mys...</td>\n",
       "      <td>[14.928600311279297, 14.104228019714355, 9.220...</td>\n",
       "      <td>[14.928600311279297, 14.104228019714355, 9.220...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                             prompt  \\\n",
       "0     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "1  dislike  GPT4 Correct User:Please comment briefly on th...   \n",
       "2     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "3  dislike  GPT4 Correct User:Please comment briefly on th...   \n",
       "4     like  GPT4 Correct User:Please comment briefly on th...   \n",
       "\n",
       "                                sycophantic_response  \\\n",
       "0  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "1  \\nThe poem explores the concept of justice and...   \n",
       "2  \\n\\nThe poem is a celebration of creativity an...   \n",
       "3  \\n\\nThe poem showcases a vivid and imaginative...   \n",
       "4  \\n\\nThe poem is a beautiful exploration of the...   \n",
       "\n",
       "                            not_sycophantic_response  \\\n",
       "0  \\n\\nThe poem vividly describes the concept of ...   \n",
       "1  \\n\\nThe poem vividly describes the concept of ...   \n",
       "2  \\n\\nThe poem is an ode to creativity and its b...   \n",
       "3  \\n\\nThe poem is an ode to creativity and its b...   \n",
       "4  \\n\\nThe poem is a celebration of chaos and mys...   \n",
       "\n",
       "                         scores_sycophantic_response  \\\n",
       "0  [14.880401611328125, 13.952696800231934, 8.905...   \n",
       "1  [16.385225296020508, 14.226066589355469, 9.904...   \n",
       "2  [13.827075004577637, 12.555858612060547, 7.499...   \n",
       "3  [15.904107093811035, 13.390772819519043, 7.679...   \n",
       "4  [14.928600311279297, 14.104228019714355, 9.220...   \n",
       "\n",
       "                     scores_not_sycophantic_response  \n",
       "0  [14.880401611328125, 13.952696800231934, 8.905...  \n",
       "1  [16.385225296020508, 14.226066589355469, 9.904...  \n",
       "2  [13.827075004577637, 12.555858612060547, 7.499...  \n",
       "3  [15.904107093811035, 13.390772819519043, 7.679...  \n",
       "4  [14.928600311279297, 14.104228019714355, 9.220...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column 'sycophancy_score' in the dataframe\n",
    "new_df['scores_sycophantic_response'] = None\n",
    "new_df['scores_not_sycophantic_response'] = None\n",
    "\n",
    "#iterate over the dataframe and get the activations for each row\n",
    "for index, row in tqdm(new_df.iterrows(), total=new_df.shape[0]):\n",
    "    question = row['prompt']\n",
    "    \n",
    "    answer = row['sycophantic_response']\n",
    "    prompt = make_prompt(question, answer)\n",
    "    activations = get_activation(prompt, reward_model, reward_tokenizer, layer)\n",
    "    #get the mean score of all the tokens corresponding to the answer of the assistant\n",
    "    sycophancy_score = probe(activations)\n",
    "    new_df.at[index, 'scores_sycophantic_response'] = sycophancy_score.squeeze().tolist()\n",
    "\n",
    "    answer = row['not_sycophantic_response']\n",
    "    prompt = make_prompt(question, answer)\n",
    "    activations = get_activation(prompt, reward_model, reward_tokenizer, layer)\n",
    "    sycophancy_score = probe(activations)\n",
    "    new_df.at[index, 'scores_not_sycophantic_response'] = sycophancy_score.squeeze().tolist()\n",
    "\n",
    "#save the dataframe\n",
    "new_df.to_csv('results/sycophancy_on_feedbacks_tests_v{}_{}.csv'.format(version, layer), index=False)\n",
    "\n",
    "new_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
