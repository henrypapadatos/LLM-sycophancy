{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import snapshot_download\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "process = psutil.Process()\n",
    "\n",
    "## Define the reward model function class\n",
    "\n",
    "class GPTRewardModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__()\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, cache_dir='/scratch/henrypapadatos', device_map=\"auto\")\n",
    "        self.config = model.config\n",
    "        self.config.n_embd = self.config.hidden_size if hasattr(self.config, \"hidden_size\") else self.config.n_embd\n",
    "        self.config.output_hidden_states=True\n",
    "        self.model = model\n",
    "        self.transformer = model.model\n",
    "        self.v_head = nn.Linear(self.config.n_embd, 1, bias=False).to(self.model.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.tokenizer.pad_token = self.tokenizer.unk_token\n",
    "        self.PAD_ID = self.tokenizer(self.tokenizer.pad_token)[\"input_ids\"][0]\n",
    "\n",
    "    def get_device(self):\n",
    "        return self.model.device\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_ids, attention_mask: torch.Size([bs, seq_len])\n",
    "        return: scores: List[bs]\n",
    "        \"\"\"\n",
    "        bs = input_ids.shape[0]\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "        )\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        scores = []\n",
    "        rewards = self.v_head(hidden_states).squeeze(-1)\n",
    "        for i in range(bs):\n",
    "            c_inds = (input_ids[i] == self.PAD_ID).nonzero()\n",
    "            c_ind = c_inds[0].item() if len(c_inds) > 0 else input_ids.shape[1]\n",
    "            scores.append(rewards[i, c_ind - 1])\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d29adcfed9f4e2cb12f2c3fccf261b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load the model and tokenizer\n",
    "reward_model = GPTRewardModel(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "reward_tokenizer = reward_model.tokenizer\n",
    "reward_tokenizer.truncation_side = \"left\"\n",
    "reward_device = reward_model.get_device()\n",
    "reward_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae8dcb0a92e44fb988a22cdca866263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GPTRewardModel(\n",
       "  (model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32000, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "  )\n",
       "  (transformer): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (v_head): Linear(in_features=4096, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = snapshot_download(\"berkeley-nest/Starling-RM-7B-alpha\", cache_dir='/scratch/henrypapadatos')\n",
    "for fpath in os.listdir(directory):\n",
    "    if fpath.endswith(\".pt\") or fpath.endswith(\"model.bin\"):\n",
    "        checkpoint = os.path.join(directory, fpath)\n",
    "        break\n",
    "\n",
    "# Load the model on the GPU  \n",
    "# reward_model.load_state_dict(torch.load(checkpoint, map_location=reward_device), strict=False)\n",
    "reward_model.load_state_dict(torch.load(checkpoint), strict=False)\n",
    "reward_model.eval().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34806, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>prompt</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>choice_label</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "      <th>activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amrozi accused his brother , whom he called \" ...</td>\n",
       "      <td>Referring to him as only \" the witness \" , Amr...</td>\n",
       "      <td>[INST]   Hello, my name is Elbert Chouinard. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290981</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              text1  \\\n",
       "0      0  Amrozi accused his brother , whom he called \" ...   \n",
       "\n",
       "                                               text2  \\\n",
       "0  Referring to him as only \" the witness \" , Amr...   \n",
       "\n",
       "                                              prompt  assistant_opinion  \\\n",
       "0  [INST]   Hello, my name is Elbert Chouinard. I...                  0   \n",
       "\n",
       "   human_opinion  choice_label  ground_truth  sycophancy  non_sense  \\\n",
       "0              0             0             1           0          0   \n",
       "\n",
       "   certainty activations  \n",
       "0   0.290981        None  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_folder = \"../../datasets\"\n",
    "file_name = \"MRPC_sycophantic.jsonl\"\n",
    "\n",
    "## Load the data\n",
    "df = pd.read_json(os.path.join(data_folder, file_name), lines=True)\n",
    "#create a column index and put it as the first column\n",
    "\n",
    "#keep only when the column 'non_sense' is equal to 0\n",
    "df = df[df['non_sense']==0]\n",
    "#drop the column 'original_idx'\n",
    "df = df.drop(columns=['original_idx'])\n",
    "df['index'] = df.index\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "print(df.shape)\n",
    "#add column for 'activations'\n",
    "df['activations'] = None\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>choice_label</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500333</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.499833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.652144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500042</td>\n",
       "      <td>0.500041</td>\n",
       "      <td>0.500042</td>\n",
       "      <td>0.500042</td>\n",
       "      <td>0.471385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       assistant_opinion  human_opinion  choice_label  ground_truth  \\\n",
       "count        6000.000000    6000.000000   6000.000000   6000.000000   \n",
       "mean            0.500333       0.501000      0.499833      0.500000   \n",
       "std             0.500042       0.500041      0.500042      0.500042   \n",
       "min             0.000000       0.000000      0.000000      0.000000   \n",
       "25%             0.000000       0.000000      0.000000      0.000000   \n",
       "50%             1.000000       1.000000      0.000000      0.500000   \n",
       "75%             1.000000       1.000000      1.000000      1.000000   \n",
       "max             1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "        sycophancy  non_sense    certainty  \n",
       "count  6000.000000     6000.0  6000.000000  \n",
       "mean      0.333167        0.0     0.652144  \n",
       "std       0.471385        0.0     0.101393  \n",
       "min       0.000000        0.0     0.503906  \n",
       "25%       0.000000        0.0     0.550607  \n",
       "50%       0.000000        0.0     0.682574  \n",
       "75%       1.000000        0.0     0.727975  \n",
       "max       1.000000        0.0     0.957278  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_number = 1000 * 6\n",
    "\n",
    "#get all the value of the column 'certainty' for ground_truth == 0\n",
    "df_false = df[df['ground_truth']==0]\n",
    "#sort the values of df_false and keep the threshold value\n",
    "df_false = df_false.sort_values(by='certainty',ascending=False)\n",
    "#pl\n",
    "\n",
    "#keep only the first threshold numebr of the values\n",
    "df_false = df_false.iloc[:keep_number//2]\n",
    "\n",
    "false_index = df_false['index'].tolist()\n",
    "\n",
    "df_true = df[df['ground_truth']==1]\n",
    "df_true = df_true.sort_values(by='certainty',ascending=False)\n",
    "df_true = df_true.iloc[:keep_number//2]\n",
    "true_index = df_true['index'].tolist()\n",
    "\n",
    "keep_index = false_index + true_index\n",
    "\n",
    "df = df[df['index'].isin(keep_index)]\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "#reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 0.92 GB\n"
     ]
    }
   ],
   "source": [
    "size = process.memory_info().rss\n",
    "print(f\"Memory usage: {size/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1001/6000 [30:02<4:01:09,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 rows\n",
      "Memory: 1.77 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2001/6000 [1:00:08<4:22:15,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 rows\n",
      "Memory: 2.39 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3001/6000 [1:30:17<4:06:17,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3000 rows\n",
      "Memory: 4.54 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4001/6000 [2:00:28<3:27:12,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4000 rows\n",
      "Memory: 4.56 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5001/6000 [2:30:45<2:04:22,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5000 rows\n",
      "Memory: 4.58 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [3:00:43<00:00,  1.81s/it]  \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with torch.no_grad():\n",
    "    #iterate through the dataframe\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        #get the input text\n",
    "        prompt = row['prompt']\n",
    "        #tokenize the input text\n",
    "        encodings_dict = reward_tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=2048,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(reward_device)\n",
    "\n",
    "        #get the model outputs\n",
    "        output = reward_model.transformer(input_ids=encodings_dict['input_ids'], attention_mask=encodings_dict['attention_mask'])\n",
    "\n",
    "        #get the last index where attention_mask is 1 - 1 to get the token corresponding to A or D\n",
    "        token_index = (encodings_dict['attention_mask'][0]==1).nonzero().tolist()[-1][0] - 1\n",
    "        selected_token = reward_tokenizer.convert_ids_to_tokens(encodings_dict['input_ids'][0])[token_index]\n",
    "        assert selected_token=='A' or selected_token=='D'\n",
    "\n",
    "        #put all the actiovations (in the tuple 'activations') to the cpu\n",
    "        activations = tuple([activation[0,token_index,:].cpu() for activation in output.hidden_states])\n",
    "        #print size of activations in MB\n",
    "        # print(f\"Size: {sum(activation.numpy().nbytes for activation in activations)/1e6:.2f} MB\")\n",
    "\n",
    "        df.at[index, 'activations'] = activations\n",
    "\n",
    "        # #get the size of the df in memory\n",
    "        # size = df.memory_usage(deep=True).sum()\n",
    "        # #print the size of the df in MB\n",
    "        # print(f\"Size: {size/1e6:.2f} MB\")\n",
    "        # size = process.memory_info().rss\n",
    "        # print(f\"Memory: {size/1e9:.2f} GB\")\n",
    "\n",
    "        # if i == 5:\n",
    "        #     raise Exception(\"Stop\")\n",
    "\n",
    "        #save the dataframe every 1000 rows\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            #save the dataframe\n",
    "            name = \"MRPC_sycophantic_activations_\"+str(i)+\".pkl\"\n",
    "            df.to_pickle(os.path.join(data_folder, name))\n",
    "            print(f\"Saved {i} rows\")\n",
    "            size = process.memory_info().rss\n",
    "            print(f\"Memory: {size/1e9:.2f} GB\")\n",
    "\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all rows\n"
     ]
    }
   ],
   "source": [
    "#save the dataframe\n",
    "name = \"MRPC_sycophantic_activations.pkl\"\n",
    "df.to_pickle(os.path.join(data_folder, name))\n",
    "print(\"Saved all rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_pickle \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMRPC_sycophantic_activations.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m test_pickle \u001b[38;5;241m=\u001b[39m test_pickle\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMRPC_sycophantic_activations.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m test_pickle\u001b[38;5;241m.\u001b[39mto_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, name))\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/pandas/core/frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5212\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5348\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5349\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5350\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5351\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5352\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5353\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5354\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5355\u001b[0m     )\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "test_pickle = pd.read_pickle(os.path.join(data_folder, \"MRPC_sycophantic_activations.pkl\"))\n",
    "\n",
    "test_pickle = test_pickle.drop(columns=['index'])\n",
    "\n",
    "name = \"MRPC_sycophantic_activations.pkl\"\n",
    "test_pickle.to_pickle(os.path.join(data_folder, name))\n",
    "\n",
    "print(test_pickle.shape)\n",
    "test_pickle.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (0, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_pickle = test_pickle[test_pickle['activations'].notna()]\n",
    "print('Initial shape: ', test_pickle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>prompt</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>choice_label</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "      <th>activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That compared with $ 35.18 million , or 24 cen...</td>\n",
       "      <td>Earnings were affected by a non-recurring $ 8 ...</td>\n",
       "      <td>[INST]   Hello, my name is Enriqueta Minick. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754915</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  That compared with $ 35.18 million , or 24 cen...   \n",
       "\n",
       "                                               text2  \\\n",
       "0  Earnings were affected by a non-recurring $ 8 ...   \n",
       "\n",
       "                                              prompt  assistant_opinion  \\\n",
       "0  [INST]   Hello, my name is Enriqueta Minick. I...                  0   \n",
       "\n",
       "   human_opinion  choice_label  ground_truth  sycophancy  non_sense  \\\n",
       "0              0             0             0           1          0   \n",
       "\n",
       "   certainty activations  \n",
       "0   0.754915        None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"../../datasets\"\n",
    "dataset_file='MRPC_sycophantic_activations.pkl'\n",
    "df = pd.read_pickle(os.path.join(data_folder, dataset_file))\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>prompt</th>\n",
       "      <th>assistant_opinion</th>\n",
       "      <th>human_opinion</th>\n",
       "      <th>choice_label</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>sycophancy</th>\n",
       "      <th>non_sense</th>\n",
       "      <th>certainty</th>\n",
       "      <th>activations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>That compared with $ 35.18 million , or 24 cen...</td>\n",
       "      <td>Earnings were affected by a non-recurring $ 8 ...</td>\n",
       "      <td>[INST]   Hello, my name is Enriqueta Minick. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754915</td>\n",
       "      <td>([tensor(0.0032), tensor(0.0014), tensor(-0.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              text1  \\\n",
       "0     64  That compared with $ 35.18 million , or 24 cen...   \n",
       "\n",
       "                                               text2  \\\n",
       "0  Earnings were affected by a non-recurring $ 8 ...   \n",
       "\n",
       "                                              prompt  assistant_opinion  \\\n",
       "0  [INST]   Hello, my name is Enriqueta Minick. I...                  0   \n",
       "\n",
       "   human_opinion  choice_label  ground_truth  sycophancy  non_sense  \\\n",
       "0              0             0             0           1          0   \n",
       "\n",
       "   certainty                                        activations  \n",
       "0   0.754915  ([tensor(0.0032), tensor(0.0014), tensor(-0.02...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.read_pickle('../../temp/run2/MRPC_sycophantic_activations.pkl')\n",
    "print(temp_df.shape)\n",
    "temp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5995, 11)\n"
     ]
    }
   ],
   "source": [
    "temp_df = temp_df.drop(columns=['index'])\n",
    "#remove rows when 'certainty' is 0.6791787148\n",
    "temp_df = temp_df[temp_df['text1']!=\"Bloomberg said on Wednesday that all 16 crew members survived and would be tested for drugs and alcohol .\"]\n",
    "print(temp_df.shape)\n",
    "\n",
    "# name = \"MRPC_sycophantic_activations.pkl\"\n",
    "# temp_df.to_pickle(os.path.join(data_folder, name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
