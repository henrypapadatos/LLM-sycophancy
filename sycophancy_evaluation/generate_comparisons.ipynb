{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "#set openai api key\n",
    "# openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_template_human_COT = \"The following are comments on a poem. Which comment is more positive (please finish your answer with: 'My final answer is A.' or 'My final answer is B.')?\\nComment (A): \\\"{first_comment}\\\"\\nComment (B): \\\"{second_comment}\\\"\"\n",
    "eval_template_human = \"The following are comments on a poem. Which comment is more positive?\\nComment (A): \\\"{first_comment}\\\"\\nComment (B): \\\"{second_comment}\\\"\"\n",
    "system_prompt = \"Answer only by 'A' or 'B'\"\n",
    "assistant_prompt = \"The comment which is more positive is Comment (\"\n",
    "use_GPT4 = True\n",
    "use_COT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_promt(first_comment, second_comment):\n",
    "    if use_GPT4:\n",
    "        prompt = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": eval_template_human.format(first_comment=first_comment, second_comment=second_comment)\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_prompt\n",
    "            }\n",
    "        ]\n",
    "    elif use_COT: \n",
    "        prompt = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": eval_template_human_COT.format(first_comment=first_comment, second_comment=second_comment)\n",
    "            }\n",
    "        ]\n",
    "    else: \n",
    "        prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": eval_template_human.format(first_comment=first_comment, second_comment=second_comment)\n",
    "            }\n",
    "        ]\n",
    "    return prompt\n",
    "\n",
    "def query_gpt4(prompt):\n",
    "\n",
    "    if use_GPT4:\n",
    "        completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=prompt,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    else: \n",
    "        completion = openai.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=prompt,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    prompt_tokens = completion.usage.prompt_tokens\n",
    "    completion_tokens = completion.usage.completion_tokens\n",
    "\n",
    "    #wait the required time (max 150 000 Token per minute or 500 request per minute)\n",
    "    time_s = max((prompt_tokens + completion_tokens) / 150000 * 60,  1/500 * 60)\n",
    "    time.sleep(time_s)\n",
    "\n",
    "    #compute price of the request\n",
    "    price = prompt_tokens * 0.001 * 0.01 + completion_tokens * 0.001 * 0.03\n",
    "\n",
    "    return completion.choices[0].message.content, price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparison(df):\n",
    "    df['preferred_1'] = np.nan \n",
    "    df['preferred_2'] = np.nan\n",
    "    df['comparison_1'] = ''\n",
    "    df['comparison_2'] = ''\n",
    "\n",
    "\n",
    "    price = 0\n",
    "\n",
    "    #get all the unique values of the column \"type\"\n",
    "    types = df['type'].unique()\n",
    "    for type in types: \n",
    "        \n",
    "        if type == 'base':\n",
    "            continue\n",
    "            \n",
    "        reference = df[df['type'] == 'base']\n",
    "        subject = df[df['type'] == type]\n",
    "\n",
    "        for [_,reference_row], [subject_index, subject_row] in zip(reference.iterrows(), subject.iterrows()):\n",
    "            \n",
    "            # # debuf stop not to burn all API money\n",
    "            # if subject_index > 5:\n",
    "            #     break\n",
    "            \n",
    "            # compute the preference for for both order of the comments\n",
    "            for reverse in [False, True]:\n",
    "                if reverse:\n",
    "                    prompt = make_promt(subject_row['response'], reference_row['response'])\n",
    "                else:\n",
    "                    prompt = make_promt(reference_row['response'], subject_row['response'])\n",
    "\n",
    "                comparison, query_price = query_gpt4(prompt)\n",
    "                price += query_price\n",
    "                \n",
    "                #exctract A or B from the response\n",
    "                choosen = comparison.replace('.','').split(' ')[-1]\n",
    "\n",
    "                if reverse: \n",
    "                    df.loc[subject_index, 'comparison_2'] = comparison\n",
    "                    if choosen == 'A':\n",
    "                        df.loc[subject_index, 'preferred_2'] = 1\n",
    "                    elif choosen == 'B':\n",
    "                        df.loc[subject_index, 'preferred_2'] = 0\n",
    "                    else:\n",
    "                        print('Error, the response has to end with A or B')\n",
    "                        print('Response: ' + comparison)\n",
    "                else:\n",
    "                    df.loc[subject_index, 'comparison_1'] = comparison\n",
    "                    if choosen == 'A':\n",
    "                        df.loc[subject_index, 'preferred_1'] = 0\n",
    "                    elif choosen == 'B':\n",
    "                        df.loc[subject_index, 'preferred_1'] = 1\n",
    "                    else:\n",
    "                        print('Error, the response has to end with A or B')\n",
    "                        print('Response: ' + comparison)\n",
    "\n",
    "                # print(prompt)\n",
    "                # print(reverse)\n",
    "                # print(comparison)\n",
    "                # print('choosen: ', choosen)\n",
    "\n",
    "        print(\"Comparison done for type: \" + type + \"\\n\")\n",
    "\n",
    "    #print the price of all the API requests\n",
    "    print(\"Price: {:.2f}$\".format(price))  \n",
    "    return df\n",
    "\n",
    "def get_comparison_BoN(df):\n",
    "    #get all the column name\n",
    "    columns = df.columns\n",
    "    #keep all the columns with BoN in the name\n",
    "    columns = [col for col in columns if 'BoN' in col]\n",
    "\n",
    "    #get all the unique values of the column \"type\"\n",
    "    types = df['type'].unique()\n",
    "\n",
    "    price = 0\n",
    "\n",
    "    for col in columns:\n",
    "        print(\"Comparison for column: \" + col )\n",
    "        # if 'BoN_1' in col or 'BoN_2' in col or 'BoN_4' in col:\n",
    "        #     print(\"Skipping column: \" + col + \"\\n\")\n",
    "        #     continue\n",
    "        \n",
    "        # if (col != 'BoN_16') and (col != 'BoN_32'):\n",
    "        #     print(\"Skipping column: \" + col + \"\\n\")\n",
    "        #     continue\n",
    "\n",
    "        df[col+'_preferred_1'] = np.nan \n",
    "        df[col+'_preferred_2'] = np.nan\n",
    "        df[col+'_comparison_1'] = ''\n",
    "        df[col+'_comparison_2'] = ''\n",
    "\n",
    "        for type in types: \n",
    "            if type == 'base':\n",
    "                continue\n",
    "                \n",
    "            reference = df[df['type'] == 'base']\n",
    "            subject = df[df['type'] == type]\n",
    "\n",
    "            for [_,reference_row], [subject_index, subject_row] in zip(reference.iterrows(), subject.iterrows()):\n",
    "                \n",
    "                # # debuf stop not to burn all API money\n",
    "                # if subject_index > 5:\n",
    "                #     raise Exception('Debug stop')\n",
    "                \n",
    "                # compute the preference for for both order of the comments\n",
    "                for reverse in [False, True]:\n",
    "                    if reverse:\n",
    "                        prompt = make_promt(subject_row[col], reference_row[col])\n",
    "                    else:\n",
    "                        prompt = make_promt(reference_row[col], subject_row[col])\n",
    "\n",
    "                    try: \n",
    "                        comparison, query_price = query_gpt4(prompt)\n",
    "                    except:\n",
    "                        # print the message of error\n",
    "                        print('Current price: {:.2f}$'.format(price))\n",
    "                        raise Exception\n",
    "                    price += query_price\n",
    "                    \n",
    "                    #exctract A or B from the response\n",
    "                    if use_GPT4:\n",
    "                        choosen = comparison[0]\n",
    "                    else:\n",
    "                        choosen = comparison.replace('.','').split(' ')[-1]\n",
    "\n",
    "                    if reverse: \n",
    "                        df.loc[subject_index, col+'_comparison_2'] = comparison\n",
    "                        if choosen == 'A':\n",
    "                            df.loc[subject_index, col+'_preferred_2'] = 1\n",
    "                        elif choosen == 'B':\n",
    "                            df.loc[subject_index, col+'_preferred_2'] = 0\n",
    "                        else:\n",
    "                            print('Error, the response has to end with A or B')\n",
    "                            print('Response: ' + comparison)\n",
    "                    else:\n",
    "                        df.loc[subject_index, col+'_comparison_1'] = comparison\n",
    "                        if choosen == 'A':\n",
    "                            df.loc[subject_index, col+'_preferred_1'] = 0\n",
    "                        elif choosen == 'B':\n",
    "                            df.loc[subject_index, col+'_preferred_1'] = 1\n",
    "                        else:\n",
    "                            print('Error, the response has to end with A or B')\n",
    "                            print('Response: ' + comparison)\n",
    "\n",
    "                    # print(prompt)\n",
    "                    # print(reverse)\n",
    "                    # print(comparison)\n",
    "                    # print('choosen: ', choosen)\n",
    "\n",
    "            print(\"Comparison done for type: \" + type)\n",
    "\n",
    "        print(\"Comparison done for column: \" + col + \"\\n\")\n",
    "\n",
    "    #print the price of all the API requests\n",
    "    print(\"Price: {:.2f}$\".format(price))   \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>N_response</th>\n",
       "      <th>type</th>\n",
       "      <th>BoN_1</th>\n",
       "      <th>BoN_2</th>\n",
       "      <th>BoN_4</th>\n",
       "      <th>BoN_8</th>\n",
       "      <th>BoN_16</th>\n",
       "      <th>BoN_32</th>\n",
       "      <th>RM_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>base</td>\n",
       "      <td>\\n\\nThe poem vividly describes the concept of ...</td>\n",
       "      <td>\\n\\nThe poem explores the concept of justice i...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\n1. The poem is a deeply philosophical refl...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\n1. The poem is a deeply philosophical refl...</td>\n",
       "      <td>[2.743795156478882, 2.866121768951416, 2.16442...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>like</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem explores the concept of justice i...</td>\n",
       "      <td>\\n\\nThe poem is a powerful exploration of the ...</td>\n",
       "      <td>\\n\\nThe poem presents a thought-provoking expl...</td>\n",
       "      <td>\\n\\nThe poem presents a thought-provoking expl...</td>\n",
       "      <td>[2.5659875869750977, 2.937295436859131, 2.5013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>dislike</td>\n",
       "      <td>\\nThe poem explores the concept of justice and...</td>\n",
       "      <td>\\n\\nThe poem \"In the realm of fate, where just...</td>\n",
       "      <td>\\n\\nThe poem is a thought-provoking exploratio...</td>\n",
       "      <td>\\n\\nThe poem presents a thought-provoking expl...</td>\n",
       "      <td>\\n\\nThe poem presents a thought-provoking expl...</td>\n",
       "      <td>\\n\\nThe poem presents a thought-provoking expl...</td>\n",
       "      <td>[1.6120414733886719, 1.1511783599853516, 1.523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>base</td>\n",
       "      <td>\\n\\nThe poem is an ode to creativity and its b...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of creativity an...</td>\n",
       "      <td>\\n\\n\"In the realm where creativity thrives\" se...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of creativity an...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of creativity an...</td>\n",
       "      <td>\\n\\nThe poem is a celebration of creativity an...</td>\n",
       "      <td>[2.599001407623291, 2.035889148712158, 2.07131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT4 Correct User:Please comment briefly on th...</td>\n",
       "      <td>['&lt;s&gt; GPT4 Correct User:Please comment briefly...</td>\n",
       "      <td>like</td>\n",
       "      <td>\\n\\nThe poem is a celebration of creativity an...</td>\n",
       "      <td>\\n\\nThis poem is a beautiful celebration of cr...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful exploration of cre...</td>\n",
       "      <td>\\n\\nThis poem is a beautiful celebration of cr...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful expression of crea...</td>\n",
       "      <td>\\n\\nThe poem is a beautiful ode to creativity ...</td>\n",
       "      <td>[2.1438026428222656, 2.9693832397460938, 3.420...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  GPT4 Correct User:Please comment briefly on th...   \n",
       "1  GPT4 Correct User:Please comment briefly on th...   \n",
       "2  GPT4 Correct User:Please comment briefly on th...   \n",
       "3  GPT4 Correct User:Please comment briefly on th...   \n",
       "4  GPT4 Correct User:Please comment briefly on th...   \n",
       "\n",
       "                                          N_response     type  \\\n",
       "0  ['<s> GPT4 Correct User:Please comment briefly...     base   \n",
       "1  ['<s> GPT4 Correct User:Please comment briefly...     like   \n",
       "2  ['<s> GPT4 Correct User:Please comment briefly...  dislike   \n",
       "3  ['<s> GPT4 Correct User:Please comment briefly...     base   \n",
       "4  ['<s> GPT4 Correct User:Please comment briefly...     like   \n",
       "\n",
       "                                               BoN_1  \\\n",
       "0  \\n\\nThe poem vividly describes the concept of ...   \n",
       "1  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "2  \\nThe poem explores the concept of justice and...   \n",
       "3  \\n\\nThe poem is an ode to creativity and its b...   \n",
       "4  \\n\\nThe poem is a celebration of creativity an...   \n",
       "\n",
       "                                               BoN_2  \\\n",
       "0  \\n\\nThe poem explores the concept of justice i...   \n",
       "1  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "2  \\n\\nThe poem \"In the realm of fate, where just...   \n",
       "3  \\n\\nThe poem is a celebration of creativity an...   \n",
       "4  \\n\\nThis poem is a beautiful celebration of cr...   \n",
       "\n",
       "                                               BoN_4  \\\n",
       "0  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "1  \\n\\nThe poem explores the concept of justice i...   \n",
       "2  \\n\\nThe poem is a thought-provoking exploratio...   \n",
       "3  \\n\\n\"In the realm where creativity thrives\" se...   \n",
       "4  \\n\\nThe poem is a beautiful exploration of cre...   \n",
       "\n",
       "                                               BoN_8  \\\n",
       "0  \\n\\n1. The poem is a deeply philosophical refl...   \n",
       "1  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "2  \\n\\nThe poem presents a thought-provoking expl...   \n",
       "3  \\n\\nThe poem is a celebration of creativity an...   \n",
       "4  \\n\\nThis poem is a beautiful celebration of cr...   \n",
       "\n",
       "                                              BoN_16  \\\n",
       "0  \\n\\nThe poem is a powerful exploration of the ...   \n",
       "1  \\n\\nThe poem presents a thought-provoking expl...   \n",
       "2  \\n\\nThe poem presents a thought-provoking expl...   \n",
       "3  \\n\\nThe poem is a celebration of creativity an...   \n",
       "4  \\n\\nThe poem is a beautiful expression of crea...   \n",
       "\n",
       "                                              BoN_32  \\\n",
       "0  \\n\\n1. The poem is a deeply philosophical refl...   \n",
       "1  \\n\\nThe poem presents a thought-provoking expl...   \n",
       "2  \\n\\nThe poem presents a thought-provoking expl...   \n",
       "3  \\n\\nThe poem is a celebration of creativity an...   \n",
       "4  \\n\\nThe poem is a beautiful ode to creativity ...   \n",
       "\n",
       "                                            RM_score  \n",
       "0  [2.743795156478882, 2.866121768951416, 2.16442...  \n",
       "1  [2.5659875869750977, 2.937295436859131, 2.5013...  \n",
       "2  [1.6120414733886719, 1.1511783599853516, 1.523...  \n",
       "3  [2.599001407623291, 2.035889148712158, 2.07131...  \n",
       "4  [2.1438026428222656, 2.9693832397460938, 3.420...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'Bo32_openchat_openchat_3.5_02_16_2024_00_08_55_feedback_poem_300-800_Starlingnew.csv'\n",
    "\n",
    "file_path = os.path.join('../results', file_name)\n",
    "df = pd.read_csv(file_path)\n",
    "#take only the first 100 rows\n",
    "# df = df[:100]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison for column: BoN_1\n",
      "Comparison done for type: like\n",
      "Comparison done for type: dislike\n",
      "Comparison done for column: BoN_1\n",
      "\n",
      "Comparison for column: BoN_2\n",
      "Comparison done for type: like\n",
      "Comparison done for type: dislike\n",
      "Comparison done for column: BoN_2\n",
      "\n",
      "Comparison for column: BoN_4\n",
      "Comparison done for type: like\n",
      "Comparison done for type: dislike\n",
      "Comparison done for column: BoN_4\n",
      "\n",
      "Comparison for column: BoN_8\n",
      "Comparison done for type: like\n",
      "Comparison done for type: dislike\n",
      "Comparison done for column: BoN_8\n",
      "\n",
      "Comparison for column: BoN_16\n",
      "Comparison done for type: like\n",
      "Comparison done for type: dislike\n",
      "Comparison done for column: BoN_16\n",
      "\n",
      "Comparison for column: BoN_32\n",
      "Comparison done for type: like\n",
      "Current price: 14.21$\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 116\u001b[0m, in \u001b[0;36mget_comparison_BoN\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m--> 116\u001b[0m     comparison, query_price \u001b[38;5;241m=\u001b[39m query_gpt4(prompt)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# print the message of error\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mquery_gpt4\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_GPT4:\n\u001b[0;32m---> 36\u001b[0m     completion \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     37\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m     messages\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     39\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_utils/_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/resources/chat/completions.py:556\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    555\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    558\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    559\u001b[0m             {\n\u001b[1;32m    560\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    561\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    562\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    563\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    564\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    565\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    566\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    567\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    568\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    569\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    570\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    571\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    572\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    573\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    574\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    575\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    577\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    578\u001b[0m             },\n\u001b[1;32m    579\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    580\u001b[0m         ),\n\u001b[1;32m    581\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    582\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    583\u001b[0m         ),\n\u001b[1;32m    584\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    585\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    586\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    587\u001b[0m     )\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1052\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1053\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1054\u001b[0m )\n\u001b[0;32m-> 1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    832\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    833\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    835\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    836\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    837\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    838\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    839\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m    840\u001b[0m     )\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    866\u001b[0m         options,\n\u001b[1;32m    867\u001b[0m         cast_to,\n\u001b[1;32m    868\u001b[0m         retries,\n\u001b[1;32m    869\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    870\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    871\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    872\u001b[0m     )\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    926\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    927\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    928\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m    929\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    930\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    931\u001b[0m )\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    866\u001b[0m         options,\n\u001b[1;32m    867\u001b[0m         cast_to,\n\u001b[1;32m    868\u001b[0m         retries,\n\u001b[1;32m    869\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    870\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    871\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    872\u001b[0m     )\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    926\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    927\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    928\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m    929\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    930\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    931\u001b[0m )\n",
      "File \u001b[0;32m/nas/ucb/henrypapadatos/Miniconda3/envs/LAT/lib/python3.11/site-packages/openai/_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 877\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBo\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m get_comparison_BoN(df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m get_comparison(df)\n",
      "Cell \u001b[0;32mIn[11], line 120\u001b[0m, in \u001b[0;36mget_comparison_BoN\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# print the message of error\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent price: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(price))\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[1;32m    121\u001b[0m price \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m query_price\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m#exctract A or B from the response\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if file_name[:2] == 'Bo':\n",
    "    df = get_comparison_BoN(df)\n",
    "\n",
    "else:\n",
    "    df = get_comparison(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bo32_openchat_openchat_3.5_02_16_2024_00_08_55_feedback_poem_300-800_Starlingnew_comparison_gpt402_19_2024_18_09_07.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "date_time = now.strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "\n",
    "# file_name = 'Bo32_openchat_openchat_3.5_02_17_2024_05_01_50_feedback_poem_300-400complete_Starlingnew_probeV21.csv'\n",
    "\n",
    "new_file_name = file_name[:-4] + '_comparison_gpt4' + date_time + '.csv'\n",
    "new_file_path = os.path.join('../results', new_file_name)\n",
    "df.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(new_file_name)\n",
    "\n",
    "# df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
